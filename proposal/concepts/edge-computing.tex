\قسمت{پردازش در لبه}

با گسترش اینترنت اشیا و مطرح شدن داده‌های حجیم در چند سال اخیر مشخص شده است که استفاده تنها از سرورهای ابری نمی‌تواند برای این پردازش مفید باشد و باعث هدر رفت منابعی چون پهنای باند و \نقاط‌خ می‌گردد.
برای پاسخ به این مشکل، بحث پردازش مِه یا \متن‌لاتین{Fog Computing} پیشنهاد شد که در آن پیشنهاد می‌شود تا پردازش‌ها به جای انجام شدن در سرورهای ابری در لبه شبکه انجام شوند.
اگر بخواهیم بهتر بیان کنیم داده‌ّهای جمع‌آوری شده به جای ارسال و پردازش در ابر در همان گرههای لبه پردازش شوند
\مرجع{Perera2017}.

اگر بخواهیم چالش‌هایی که در اینترنت اشیا باعث روی آوردن به پردازش در لبه و مه شده است را جمع‌بندی کنیم
\مرجع{Angel2021}:
\شروع{فقرات}
\فقره \متن‌سیاه{تاخیر کم}: برنامه‌های اینترنت اشیا و سیستم‌های کنترل صنعتی خواهان تاخیر در بازه چند میلی‌ثانیه هستند که به سختی در مدل ابری حاضر قابل برآورده شدن است.
\فقره \متن‌سیاه{پهنای باند بالای شبکه}: افزایش دستگاه‌های اینترنت اشیا باعث تولید حجم بالایی از داده شده است که ممکن است با توجه به پهنای باند زیادی که برای
انتقال این داده‌ها به ابر مصرف می‌شود یا حذف آن‌ها برای جلوگیری از نقص حریم خصوصی در نهایت
بدون استفاده باشند، بنابراین بهتر است که با آن‌ها به صورت محلی برخورد شود.
\فقره \متن‌سیاه{منابع محدود}: بسیار از دستگاه‌های متصل در اینترنت اشیا توانایی ارتباط مستقیم با ابر به خاطر منابع محدود را ندارند. عموما چنین ارتباط‌های پردازش زیاد و پروتکل‌های پیچیده‌ای را انتظار دارد.
\فقره \متن‌سیاه{همپوشانی فناوری عملیات و فناوری اطلاعات}: در سیستم‌های صنعتی به هم رسیدن فناوری اطلاعات و فناوری عملیات نیازمندی‌های جدیدی را ایجاد کرده است. با توجه به اینکه سیستم‌های آفلاین
می‌تواند باعث از دست رفتن سود تجارت یا آزار مشتریان شود، سیستم‌های سایبر فیزیکال معاصر می‌بایست به صورت پیوسته و امن عملیاتی باشند. بنابراین به روزرسانی‌های نرم‌افزاری و سخت‌افزاری باعث ایجاد نگرانی می‌گردد.
\فقره \متن‌سیاه{ارتباط منقطع}: وقتی دستگاه‌هایی در اینترنت اشیا از ارتباط منقطع استفاده می‌کنند فراهم آوردن یک سرویس بدون قطعی ابری برای آن‌ها دشوار خواهد بود.
\فقره \متن‌سیاه{توزیع جغرافیایی}: بسیاری از اشیا مشتمل بر سرویس‌هایی از منابع پردازشی و ذخیره‌سازی هستند، که در مناطق جفرافیایی بزرگی پراکنده هستند. بنابراین قراردادن آن‌ها در محلی که بتواند به نیازهای اینترنت اشیا پاسخ دهد
دشوار خواهد بود.
\فقره \متن‌سیاه{حساس به متن}: داده‌هایی با زمینه محلی می‌بایست برای برنامه‌های اینترنت اشیا در دسترس و قابل پردازش باشد که برای آن فاصله فیزیکی میان اشیا و ابر مرکزی مشکل‌زا است.
\فقره \متن‌سیاه{امنیت و حریم‌خصوصی}: راه‌کارهای امنیت سایبری حاضر نشان داده‌اند که برای مدیریت برنامه‌های کاربردی اینترنت اشیا با توجه به رشد چالش‌های امنیتی پاسخگو نیستند.
\پایان{فقرات}

در پردازش مِه از یک معماری خاص پیروی نمی‌شود و هدف سوهی پردازش به سمت لبه است. انتظار می‌رود با استفاده از لبه در پردازش حجم داده‌ای که نیاز به نگهداری و پردازش دارد به میزان قابل مدیریت برسد.
از سوی دیگر پردازش در لبه می‌تواند تاخیر را کاهش داده و دسترسی‌پذیری را افزایش دهد. پردازش در لبه در خانه‌های هوشمند سال‌ها است که مورد استفاده قرار گرفته است اما برای پی بردن به ویژگی‌های پردازش در لبه
نیاز است که آن در کاربردها پیچیده‌تر مانند شهر هوشمند ارزیابی کرد
\مرجع{Perera2017}.

در پردازش مه، داده‌های مختلف در اینترنت اشیا می‌توانند به محل‌های مناسب با توجه به نیازمندی‌های کارایی، جهت پردازش بیشتر هدایت شوند. مثلا داده‌هایی با الویت بالا که نیاز است به موقع به آن‌ها رسیدگی شود،
می‌توانند در گرههای لبه پردازش شوند که نزدیک‌ترین به دستگاه‌هایی هستند که این داده‌ها را تولید کرده است. داده‌هایی با الویت پایین که به تاخیر حساس نیستند می‌توانند در جهت پردازش بیشتر به گرههای تجمع‌کننده
برای پردازش بیشتر ارسال شوند.
یکی از چالش‌های استفاده از پردازش مه، چگونگی مدیریت و تخصیص منابع پردازش لبه است. از سوی دیگر چگونگی تخصیص این منابع به اشیا نیز خود چالش دیگری است
\مرجع{Lin2017}.

مساله ارتباطه منابع پردازش لبه و اشیا، باعث رضایت‌مندی کاربران می‌شود بنابراین در پردازش لبه یک مساله بیشینه‌سازی رضایت‌مندی کلی با توجه به محدودیت منابع پردازشی خواهد بود
که می‌توان آن را در قالب یک مساله بهینه‌سازی مطرح کرد. در این مساله نیاز است که ارتباطی میان رضایت‌مندی کاربر و منابع تخصیص‌یافته بدست آید که پژوهش \مرجع{Lin2017} از مدل
لگاریتیمی استفاده کرده است.
از سوی دیگر، همانطور که بیان شد چالش دیگر پردازش مه، مربوط به مدیریت منابع است. در پردازش مه ممکن است لبه‌، پردازش‌ها را با توجه به کمبود منابع به سمت لبه‌های همسایه هدایت کنند.
در این شیوه هدف کاهش هزینه (تاخیر یا \نقاط‌خ) است. برای این چالش نیز می‌توان از یک مساله بهینه‌سازی استفاده کرد
\مرجع{Lin2017}.

\زیرقسمت{\متن‌لاتین{Mobile Computing}}

پردازش همراه، پردازشی است که روی تلفن‌های همراه، تبلت‌ها و یا لپتاب‌ها صورت می‌گیرد. دستگاه‌های همراه مزایای زیادی را برای کاربرانشان به همراه دارند اما هنوز
محدودیت‌هایی به خاطر توان پردازشی پایین، باتری یا حافظه‌شان، که از اندازه کوچکشان و فعالیت آن‌ها با شبکه روشن یا خاموش منشا می‌گیرد، دارند.
این مشکلات باعث شده است که پردازش همراه برای برنامه‌هایی که نیاز به تاخیر پایین و قابلیت اطمینان آن هم هنگامی که حجم زیادی داده برای ذخیره‌سازی و پردازش دارند، کافی نباشد
\مرجع{Angel2021}.

\زیرقسمت{\متن‌لاتین{Mobile Cloud Computing}}

پردازش همراه ابری یا اختصارا \متن‌لاتین{MCC} بیان می‌کند که پردازش ابری در ترکیب با برنامه‌های موبایل قرار گرفته و ماژول‌های پردازشی پیچیده در ابر پردازش شوند.
در این شیوه پردازش و ذخیره‌سازی به دور از موبایل صورت می‌گیرد نه تنها صاحبان تلفن‌های هوشمند بلکه مشترکان زیادی از موبایل از آن بهره می‌برند.
با انجام تسک‌های محاسباتی بزرگ بر روی ابر با استفاده از \متن‌لاتین{MCC} مصرف باتری دستگاه‌ها بهبود میابد.
با این وجود با استفاده از فناوری‌های ارتباط سلولی، انتقال اطلاعات در فواصل طولانی به/از شبکه هسته، افزایش تاخیر، تغییرات تاخیر و سربار شبکه را در پی دارد.
برای غلبه به این مساله، پردازش و فیلترینگ داده می‌بایست در نزدیکی منبع آن صورت بگیرد، بحثی که در پردازش مه و پردازش همراه لبه (\متن‌لاتین{MEC}) صورت می‌پذیرد
\مرجع{Angel2021}.

\زیرقسمت{\متن‌لاتین{Cloud of Things}}

در ابر اشیا، دستگاه‌های اینترنت اشیا در کنار یکدیگر یک ساختار ابر مجازی را شکل می‌دهند. در این حالت پردازش روی یک مجموعه‌ای از منابع که ساخته شده از اشیا است، صورت می‌پذیرد.
این امر با پردازش غباری متفاوت است چرا که در آن پردازش روی مجموعه‌ای از اشیا صورت می‌پذیرد
\مرجع{Angel2021}.

\زیرقسمت{\متن‌لاتین{Mist Computing}}

پردازش غباری اولین لایه محاسباتی است که اجازه محاسبه، ذخیره‌سازی و شبکه‌سازی را از اشیا تا مِه می‌دهد. در پردازش غباری ما محدود به دستگاه‌های همراه نیستیم بلکه اجزای پیرامونی (حسگرها و عملگرها)
ظرفیت پیش‌پردازش داده‌ها قبل از ارسال آن‌ها به ابر را دارند. پردازش غباری در سیستم‌های بزرگ اینترنت اشیا بسیار کمک می‌کند و می‌تواند کارایی محاسباتی در لبه را بهبود بخشد
\مرجع{Angel2021}.

\زیرقسمت{\متن‌لاتین{Edge Computing}}

همانطور که بیان شد پردازش لبه فناوری‌هایی را مشخص می‌کند که پردازش در لبه شبکه را برای داده‌های ارسال از سرویس‌های ابری و داده‌های ارسالی از سرویس‌های اینترنت اشیا ممکن می‌سازند.
این مدل پردازشی، شبکه‌ی ابری را به واسطه‌ی اضافه کردن پردازش، شبکه و منابع در لبه شبکه در نزدیکی منبع داده‌ها، برای برآورده ساختن نیازهای حیاتی سرویس‌های همزمان، برنامه‌های هوشمند،
امنیت و حریم خصوصی در کنار نیازمندی‌های شبکه‌ای چون تاخیر کم و پهنای باند بالا، گسترش می‌دهد
\مرجع{Angel2021}.

در مقابل پردازش ابری، پردازش در لبه برای پردازش‌های هوشمند و همزمان در مقیاس کوچک کارایی بیشتری دارد. این نوع پردازش ریسک‌های انتقال بر بستر شبکه را نداشته و می‌تواند امنیت داده‌ها تضمین کند.
ارتباط میان لبه و ابر عموما در یک مدل سه‌لایه‌ای مشتمل بر گرههای انتهایی یا \متن‌لاتین{Terminal} (سنسورها، عملگرها و تلفن‌های هوشمند)،
لبه یا \متن‌لاتین{Edge} (\متن‌لاتین{Base Station}ها، \دروازهها، سوئیچ‌ها، مسیریاب‌ها و \متن‌لاتین{Access Point}ها)
و ابر یا \متن‌لاتین{Cloud} مشخص می‌گردد
\مرجع{Angel2021}.

\زیرقسمت{\متن‌لاتین{Multi-Access Edge Computing}}

استاندارد \متن‌لاتین{Mobile Edge Computing} یا اختصارا \متن‌لاتین{MEC} به وسیله‌ی \متن‌لاتین{ETSI} برای استفاده از پردازش ابری و کارکردهای فناوری اطلاعات در شبکه‌ی دسترسی رادیویی
در حیطه‌ی مشترکین تلفن همراه مطرح شد. در سال ۲۰۱۷ با توجه به استقبال اپراتورهای غیرسلولی، \متن‌لاتین{ETSI} نام این استاندارد را به \متن‌لاتین{Multi-Access Edge Computing}
تغییر داد. بنابراین \متن‌لاتین{MEC} ادامه پردازش موبایل به وسیله‌ی پردازش لبه برای رساندن منابع پردازشی و ذخیره‌سازی به دستگاه‌های موبایل با منابع و توان محدود است
\مرجع{Angel2021}.

در \متن‌لاتین{MEC} یک سرور ابری در \متن‌لاتین{Base Station} شبکه سلولی، مستقر می‌شود. این سرور کارهایی نظیر بهبود کارایی برنامه‌های کاربردی
با نصب در \متن‌لاتین{Base Station}ها، \متن‌لاتین{MEC} می‌تواند تاخیر کم، نزدیکی به کاربر، اطلاع از موقعیت و توزیع جغرافیایی را بدست آورد.
اما در این شیوه به یک سرور اختصاصی برای \متن‌لاتین{MEC} نیاز است.
با افزایش تقاضا در طول زمان، گسترش‌پذیری مساله مهمی است که می‌بایست به آن پرداخته شود.
در نهایت \متن‌لاتین{MEC} با فراهم آوردن تاخیر پایین، قابلیت اطمینان و کارایی برای برنامه‌های متفاوتی مفید واقع می‌شود و می‌تواند کاملا جایگزین \متن‌لاتین{MCC} باشد
\مرجع{Angel2021}.

\زیرقسمت{\متن‌لاتین{Cloudlet}}

مفهوم \متن‌لاتین{Cloudlet} توسط محققین دانشگاه \متن‌لاتین{Carnegie Mellon} پیشنهاد شد که یک کلاستر یا مرکز داده‌ای کوچک
که نزدیک به کاربران موبایل قرار گرفته و قادر به محاسبات و ذخیره‌سازی است.
این مفهوم اشتراکات زیادی با \متن‌لاتین{MEC} و \متن‌لاتین{MMC} دارد اما به \متن‌لاتین{MMC} نزدیکتر است
\مرجع{Angel2021}.

\زیرقسمت{\متن‌لاتین{Fog Computing}}

ایده‌ی پردازش در لبه از سال ۲۰۰۰ وجود داشته است. مفاهیم مرتبطی مانند \متن‌لاتین{Cloudlet} در سال ۲۰۰۹ پیشنهاد شدند.
عبارت \متن‌لاتین{Fog Computing} توسط محققین \متن‌لاتین{Cisco} در سال ۲۰۱۲ گسترش یافت.
هر دو مفهوم \متن‌لاتین{Cloudlet} و \متن‌لاتین{Fog Computing} مرتبط بوده و در سطح لبه فعالت می‌کنند با این حال
\متن‌لاتین{Cloudlet}ها در شبکه‌های موبایل مستقر می‌شوند و \متن‌لاتین{Fog Computing} با اشیا مرتبط سر و کار دارد
\مرجع{Angel2021}.

\متن‌لاتین{Fog Computing} قالبا به عنوان شکلی از پردازش در لبه حساب می‌شود.
\متن‌لاتین{Fog Computing} در واقع منابع توزیع شده پردازشی، شبکه‌ای و ذخیره‌سازی را نزدیکتر به کاربران مستقر می‌کنند.
\متن‌لاتین{Cisco} از \متن‌لاتین{Fog Computing} به عنوان یک زیرساخت کاملا مجازی‌سازی شده یاد می‌کند که سرویس‌های محاسباتی، ذخیره‌سازی و شبکه‌ای
را بین مراکز داده‌ای ابری مرسوم و دستگاه‌های انتهایی با عموما (و نه همیشه) قرارگیری در لبه شبکه فراهم می‌کند.
\متن‌لاتین{Fog Computing} از تکنیک توزیع‌شدگی، که با پردازش لبه آغاز شده بود، به وسیله‌ی گرههایی که
می‌توانند در هرجایی میان ابر و دستگاه‌های انتهایی مستقر شوند،
برای غلبه بر محدودیت‌های پردازش ابری متمرکز استفاده می‌کند
\مرجع{Angel2021}.

\زیرزیرقسمت{ویژگی‌های اساسی}

ویژگی‌های اساسی در \متن‌لاتین{Fog Computing} را می‌توان به شرح زیر برشمارد
\مرجع{Angel2021}:

\شروع{فقرات}
\فقره \متن‌سیاه{تاخیر کم}: نزدیکی گرههای مِه به دستگاه‌های انتهایی که داده را تولید می‌کنند (مانند حسگرها و عملگرها) باعث می‌شود که پاسخ و آنالیز سریع‌تری
نسبت به مرکز داده‌ای ابری متمرکز حاصل شود.
\فقره \متن‌سیاه{صرفه‌جویی در پهنای باند}: از آنجایی که مدل مِه اجازه پردازش و ذخیره‌سازی میان ابر مرسوم و دستگاه‌های انتهایی را می‌دهد،
پیش‌پردازش‌هایی با پیچیدگی کم می‌توانند به صورت محلی انجام شوند. با این کار انتقال داده در اینترنت به میزان قابل توجهی کاهش پیدا می‌کند.
با انتقال یافتن، میزان مورد نیاز از داده به ابر انتقال بر بستر شبکه و مصرف پهنای باند کاهش پیدا می‌کند و این برای عصر مَه داده‌ها مفید خواهد بود.
\فقره \متن‌سیاه{\متن‌لاتین{Multi-tenancy}}: با وجود یک زیرساخت گسترده و توزیع شده امکان \متن‌لاتین{multi-tenancy} در محیط‌های محدود شده ممکن می‌شود.
\فقره \متن‌سیاه{پشتیبانی از جابجایی}: به دلیل تعامل مستقیم میان برنامه‌های مِه و دستگاه‌های متحرک، کنترل بیشتری بر این دستگاه‌ها وجود دارد.
بنابراین مدل مِه کنترل بهتری روی کاربرانی با دستگاه‌های متحرک برای مدیران فراهم می‌آورد و دسترسی به اطلاعات و پاسخ به نیازهای جابجایی مبتنی بر موقعیت
را بهبود می‌دهد که در نهایت منجر به بهبود کیفیت سرویس‌ها و کارایی سیستم می‌شود.
\فقره \متن‌سیاه{تعامل همزمان}: برخلاف ابر، برنامه‌های کابردی مِه می‌توانند سرویس‌های همزمان را به خاطر تاخیر پایینی که دارند، ارائه کنند.
\فقره \متن‌سیاه{آگاهی از زمینه}: گرهها و دستگاه‌ها در دنیای مِه از وضعیت مکانی آگاه هستند.
\فقره \متن‌سیاه{توزیع‌شدگی گسترده جغرافیایی}: مدل معماری توزیع شده مِه باعث می‌شود راه‌اندازی گرههای پراکنده که به صورت جغرافیایی پخش شده‌اند،
سریعتر صورت بگیرد. این باعث می‌شود آنالیز داده‌ّها در نقطه نزدیکتری صورت بگیرد، پردازش داده سریعتر باشد و تصمیم‌گیری همزمان و سرویس‌های مبتنی
بر موقعیت بهبود پیدا کنند.
\فقره \متن‌سیاه{شبکه دسترسی بی‌سیم}: با وجود اینکه مِه در محیط‌های باسیم نصب می‌شود اما برای شبکه‌های بی‌سیم اینترنت اشیا هم مناسب است.
\فقره \متن‌سیاه{پشتیبانی از تنوع}: زیرساخت مِه شامل خط‌های ارتباطی پرسرعت به مرکز داده‌ای و دسترسی بی‌سیم به دستگاه‌های لبه است.
گرههای مِه به صورت مجازی یا فیزیکی وجود دارند و رابط سرویس‌ها فوق العاده منعطف بوده و می‌تواند به صورت باسیم یا بدون سیم با تنظیماتی که از طرف
سازندگان مختلف نرم‌افزاری یا سخت‌افزاری می‌آیند، فعالیت کند. این گرهها نیازهای با تاخیر پایین برنامه‌هایی که به صورت جهانی توزیع شده‌اند را برآورده می‌کنند.
\فقره \متن‌سیاه{آنالیز همزمان}: با پردازش و جمع‌آوری داده‌ها در نزدیکی منابعشان، پردازش همزمان ممکن می‌شود.
\فقره \متن‌سیاه{پشتیانی از کاربردهای صنعتی}: با توجه انجام پردازش و آنالیز به صورت همزمان، کاربردهای صنعتی منافع بسیار دریافت می‌کنند.
\فقره \متن‌سیاه{امنیت و حریم خصوصی}: گرههای مِه پردازش را به نزدیکی مشتریان نهایی می‌آورند، در حالی که حریم خصوصی و امنیت داده‌های حساس و خصوصی
را به واسطه کنترل دسترسی، رمزگذاری و بررسی یکپارچی تضمین می‌کنند.
\فقره \متن‌سیاه{مصرف توان پایین}: گرههای مِه به صورت مکانی توزیع شده‌اند و نیازی به سیستم‌های خنک کننده ندارند، پردازش مِه دوستار اکولوژیک است.
ارتباطات در مسافت‌های پایین و استفاده از قوانین مدیریت انرژی مشخصا مصرف انرژی در ارتباطات را کاهش می‌دهد.
\فقره \متن‌سیاه{گسترش‌پذیری}: پردازش مِه قابلیت گسترش و تطبیق‌پذیری با شرایط مختلف را دارد.
\فقره \متن‌سیاه{همکنش‌پذیری و فدراسیون ذاتی}: با توجه به تنوع ذاتی، گرههای مِه از سازندگان مختلفی بوده و به صورت کلی با تنظیمات مختلفی نصب می‌گردند.
برای تعامل با دستگاه‌هایی از سازندگان مختلف، پردازش مِه می‌بایست همکنش‌پذیری با سرویس‌های فدرال‌شده از دامنه‌های مختلف را داشته باشد.
بنابراین، پردازش مِه برای همکنش‌پذیری و همکاری میان منابع و دستگاه‌های مختلف می‌بایست سیاست‌هایی برای مدیریت منابع داشته باشد.
\پایان{فقرات}

\زیرزیرقسمت{معماری}

ارائه معماری مِه حوزه‌ی مهمی از تحقیقات بوده است. بیشتر تحقیقات یک مدل سه‌لایه‌ای را پیشنهاد کرده‌اند.
مدل $n$-لایه‌ای نیز توسط کنسرسیوم \متن‌لاتین{OpenFog} به عنوان بهبودی بر مدل سه‌لایه‌ای پیشنهاد شده است
\مرجع{Angel2021}.

در شکل \رجوع{شکل: معماری مه سه‌لایه‌ای} مدل سه‌لایه‌ای پایه نمایش داده می‌شود که در آن پردازش مِه به عنوان
یک افزونه در پردازش ابری مطرح است و لایه مِه به عنوان یک لایه میانه، بین ابر و دستگاه‌های اینترنت اشیا قرار گرفته است
\مرجع{Angel2021}.

\شروع{شکل}
\درج‌تصویر[width=.5\textwidth]{./img/fog-3-layer-arch.png}
\تنظیم‌ازوسط
\شرح{معماری مِه مرسوم سه‌لایه‌ای \مرجع{Angel2021}}
\برچسب{شکل: معماری مه سه‌لایه‌ای}
\پایان{شکل}

\متن‌سیاه{لایه اینترنت اشیا} نزدیک‌ترین لایه به تنظیمات فیزیکی کاربر انتهایی است. حسگرها، ماشین‌های هوشمند، هواپیماهای بی‌سرنشین،
تلفن‌های هوشمند، تبلت‌ها و دیگر دستگاه‌ها این لایه را شکل داده‌اند. با این که برخی از این دستگاه‌ها توان پردازشی دارند، در این لایه
به عنوان حسگر هوشمند استفاده می‌شوند. به صورت کلی این دستگاه‌ها، برای حس کردن و انتقال داده‌ها
به لایه بالاتر به منظور استفاده از منابع ذخیره‌سازی و پردازشی، به صورت جغرافیایی پراکنده هستند
\مرجع{Angel2021}.

\متن‌سیاه{لایه مِه} متشکل از تعداد زیادی گره مِه بوده و پایه‌ای برای معماری پردازش مِه را فراهم می‌آورد.
با توجه به گفته کنسرسیوم \متن‌لاتین{OpenFog} گرههای مِه می‌توانند المان‌های مجازی یا فیزیکی شبکه باشند که سرویس‌های مِه را برقرار می‌کنند.
بنابراین، گرههای مِه ارتباط مستقیم در جهت گسترش سرویس‌ها به دستگاه‌های انتهایی دارند و از سوی دیگر گرههای مِه به زیرساخت ابری متصل بوده تا بتوانند
مزایا آن را دریافت و سرویس‌های آن را فراهم کنند
\مرجع{Angel2021}.

\متن‌سیاه{لایه ابر} که بخش عمده‌ای از آن را زیرساخت متمرکز ابری تشکیل داده است از سرورهای زیادی تشکیل شده است که با قابلیت‌های ذخیره‌سازی و پردازشی
پیشرفته می‌توانند گستره‌ای از سرویس‌های مختلف را ارائه دهند. برخلاف معماری متدوال پردازش ابری، مدل مِه می‌تواند بار روی منابع ابری را با انتقال موثر سرویس‌های پردازشی
از لایه ابر به مِه، سبک کند و کارایی را بهبود بخشد
\مرجع{Angel2021}.

کنسرسیوم \متن‌لاتین{OpenFog} معماری $n$-لایه‌ای که در شکل \رجوع{شکل: معماری مه n لایه‌ای} آورده شده است، را پیشنهاد می‌کند.
هدف اصلی این معماری ارائه راهنمایی‌های استانداری است که می‌توان از آن‌ها برای پیاده‌سازی پردازش مِه در شرایطی که از پیش مشخص شده است، استفاده کرد.
از آنجایی که سیستم‌های مِه به واسطه سناریو مشخصی استقرار پیدا می‌کنند، عناصر هسته این معماری در همه این استقرارها دیده می‌شوند.
اشیا، گرههای مِه و ابر اجزای اصلی این ایده هستند. در کنار آن‌ها، چندید لایه از گرههای مِه ممکن است برای ساخت لایه مِه استفاده شوند.
زمانی که فاصله این گرهها از دستگاه‌های انتهایی بیشتر شود، توان پردازشی و هوشمندی آن‌ها بیشتر می‌شود
\مرجع{Angel2021}.

در معماری $n$-لایه‌ای می‌توان گرههای مِه را با توجه به نزدیکی‌شان به اشیا یا ابر دسته‌بندی کرد
\مرجع{Angel2021}:
\شروع{فقرات}
\فقره \متن‌سیاه{پایین‌ترین رده}: با تمرکز اصلی بر جمع‌آوری، نرمال‌سازی و بدست آوردن داده‌های حسگرها و عملگرهایی که توسط گرههای مِه مدیریت می‌شوند.
\فقره \متن‌سیاه{رده میانی}: فیلتر کردن، فشرده‌سازی و تغییر داده‌های دریافت شده از لایه‌ی پایینی وظیفه‌ی گرههای مِه در این رده است. به صورت میانگین
این گرهها در آنالیز داده‌ها بهتر عمل می‌کنند.
\فقره \متن‌سیاه{بالاترین رده}: تجمیع داده‌ها و استخراج دانش از آن‌ها هدف گرهها در این رده است.
\پایان{فقرات}

پردازش مِه برای پردازش جریان یا \متن‌لاتین{Stream Processing} داده‌ها تاکید دارد که کمترین داده مرتبط در لبه پردازش و ذخیره شود
چرا که همه داده‌های تولید شده لزوما کاربردی نیستند.
برخی از برنامه‌های کاربردی نیاز به پاک کردن داده‌ها دارند که می‌تواند با ذخیره کردن میانگین یک ساعت یا یک دقیقه از داده‌ها در زمانی که سنسور
هر ثانیه داده تولید می‌کند صورت بگیرد
\مرجع{Angel2021}.

\شروع{شکل}
\درج‌تصویر[width=.5\textwidth]{./img/fog-n-layer-arch.png}
\تنظیم‌ازوسط
\شرح{معماری مِه‌$n$-لایه‌ای \مرجع{Angel2021}}
\برچسب{شکل: معماری مه n لایه‌ای}
\پایان{شکل}
